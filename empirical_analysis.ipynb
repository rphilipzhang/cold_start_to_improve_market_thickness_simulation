{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056d17db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T01:53:05.006727Z",
     "start_time": "2022-07-31T01:53:03.981075Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import sys\n",
    "stdin, stdout, stderr = sys.stdin, sys.stdout, sys.stderr\n",
    "sys.stdin, sys.stdout, sys.stderr = stdin, stdout, stderr\n",
    "import pandas as pd \n",
    "import pylab, math\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from datetime import time, datetime\n",
    "import datetime, time\n",
    "import datetime as dt\n",
    "import warnings\n",
    "from sklearn import metrics\n",
    "from IPython.core.pylabtools import figsize\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy import stats\n",
    "from scipy.stats.mstats import winsorize\n",
    "from numpy.random import permutation\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import FixedFormatter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d01bf2",
   "metadata": {},
   "source": [
    "# Empirical Analysis\n",
    "\n",
    "## Table of contents\n",
    "* [General Info](#general-info-emp)\n",
    "* [Files](#files-emp)\n",
    "* [Instruction to produce figures, tables, results](#instr)\n",
    "* [Dictionary of datasets](#dic-data)\n",
    "\n",
    "\n",
    "<a id='general-info-emp'></a>\n",
    "## General Info \n",
    "xxxx\n",
    "\n",
    "\n",
    "<a id='files-emp'></a>\n",
    "## Files\n",
    "* [empirical_analysis.ipynb](https://github.com/zikunye2/cold_start_to_improve_market_thickness_simulation/blob/main/empirical_analysis.ipynb): The main empirical analysis code. \n",
    "\n",
    "* [retention_data.csv'](https://github.com/zikunye2/cold_start_to_improve_market_thickness_simulation/blob/main/retention_data.csv) This dataset contains observational data before the experiment. Each row records the basic information ('imp', 'click_cnt', 'cvr_cnt', 'target_cost', 'cost_total', 'target_bid'), aggregated at day level ('p_date') of a specific ad (unit_id).\n",
    "\n",
    "* [randomization_check_data_block.csv](https://github.com/zikunye2/cold_start_to_improve_market_thickness_simulation/blob/main/randomization_check_data_block.csv) This dataset is used for randomization check and constains ad performance data before the experiments. Each row records the basic information ('target_cost','cost_total','cvt_cnt','auto_cpa_bid','target_bid','imp','click'), aggregated at day level ('p_date') of a specific ad ('unit_id') with the field ('unit_tag') indicating whether the ad is in the treatment group or not.\n",
    "\n",
    "* [exp_short_term_results.csv](https://github.com/zikunye2/cold_start_to_improve_market_thickness_simulation/blob/main/exp_short_term_results.csv) This dataset contains the ad performance data during the experiment. Each row records the basic performance information aggregated at hour level ('p_date','p_hourmin') of a specific ad ('unit_id') with assigned conditions ('exp_tag','unit_tag').\n",
    "\n",
    "* [exp_cost_results.csv](https://github.com/zikunye2/cold_start_to_improve_market_thickness_simulation/blob/main/exp_cost_results.csv) This dataset contains the revenue performance aggregated at hour level during the experiment.\n",
    "\n",
    "<a id='instr'></a>\n",
    "## Instruction to produce figures, tables, results\n",
    "* [Figure 1 Retention Rate] can be produced by the Block-[Figure 1 with observational data] in code [empirical_analysis.ipynb](https://github.com/zikunye2/cold_start_to_improve_market_thickness_simulation/blob/main/empirical_analysis.ipynb)\n",
    "* [Table 2 The Short-Term Effects of oSBL] can be produced by Block-[Section 6.1 Short-Term Performance of Our oSBL Algorithm] in code [empirical analysis.ipynb](https://github.com/zikunye2/cold_start_to_improve_market_thickness_simulation/blob/main/empirical_analysis.ipynb)\n",
    "* [Table 3 The Long-Term Effects of oSBL] and Block-[Figure 6 Effect of oSBL on Market Thickness] can be produced by [Section 6.2 Long-term effects of oSBL] in code [empirical analysis.ipynb](https://github.com/zikunye2/cold_start_to_improve_market_thickness_simulation/blob/main/empirical_analysis.ipynb)\n",
    "* [Figure 7 Global Treatment Effect of oSBL on Advertising Revenue] can be produced by Block-[Section 6.3 Global Treatment Effect of Our oSBL Algorithm on Advertising Revenue] in code [empirical analysis.ipynb]\n",
    "* [Table 6 Randomization Check of the Experiment] can be produced by Block-[Section 5 Randomization check of field experiments] in code-[empirical analysis.ipynb](https://github.com/zikunye2/cold_start_to_improve_market_thickness_simulation/blob/main/empirical_analysis.ipynb)\n",
    "* [Figure 9, 10, 11] can be produced by Block-[Section 6.3 Global Treatment Effect of Our oSBL Algorithm on Advertising Revenue] in code [empirical analysis.ipynb](https://github.com/zikunye2/cold_start_to_improve_market_thickness_simulation/blob/main/empirical_analysis.ipynb)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<a id='dic-data'></a>\t\n",
    "## Dictionary of datasets\n",
    "| Column        | Meaning                            |\n",
    "|---------------|------------------------------------|\n",
    "| imp_id        | impression ID                      |\n",
    "| unit_id       | ad ID                              |\n",
    "| unit_tag      | treatment condition of ad          |\n",
    "| exp_tag       | treatment condition of impression  |\n",
    "| p_date        | date                               |\n",
    "| p_hourmin     | hour                               |\n",
    "| pxtr          | predicted ctr*cvr                  |\n",
    "| retention_cnt | # of retention days                |\n",
    "| cvt_cnt       | # of conversions during cold start |\n",
    "| click         | # of clicks                        |\n",
    "| imp           | # of impressions                   |\n",
    "| auto_cpa_bid  | real-time bid                      |\n",
    "| target_bid    | bid set by advertisers             |\n",
    "| cost_total    | real cost of ads                   |\n",
    "| target_cost   | expected cost of ads               |\n",
    "\n",
    "\n",
    "\n",
    "# Simulation System for Cold Start and Experimentation in Online Advertising\n",
    "\n",
    "We provide the Python code of the simulation system built in [Ye et al. (2022)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3702786). See Appendix D.1 of the paper for details of the simulation system. Please contact the authors of [Ye et al. (2022)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3702786) if you have any questions or suggestions.\n",
    "\n",
    "\n",
    "## Table of contents\n",
    "* [General Info](#general-info)\n",
    "* [Files](#files)\n",
    "* [Simulation Details](#simulation-details)\n",
    "\n",
    "\n",
    "<a id='general-info'></a>\n",
    "## General Info \n",
    "This project contains the code (as Jupyter Notebooks) and data inputs of the simulation system of the paper [Ye et al. (2022)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3702786). The goal of releasing the code and data is to help interested scholars get deeper understanding on the operational details of the online advertising system, and the implementation of the single- and two-sided experiments studied in [Ye et al. (2022)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3702786).\n",
    "\n",
    "<a id='files'></a>\n",
    "## Files\n",
    "* [cold_start_simulation.ipynb](https://github.com/zikunye2/cold_start_to_improve_market_thickness_simulation/blob/main/cold_start_simulation.ipynb): The main simulation code. \n",
    "* [ctr_bid_data.npy](https://github.com/zikunye2/cold_start_to_improve_market_thickness_simulation/blob/main/ctr_bid_data.npy): The sampled data of click-through rates (CTR) and bid prices (to protect data security, these quantities are re-scaled by a random multiplier), 300 observations in total.\n",
    "* [simulation_output](https://github.com/zikunye2/cold_start_to_improve_market_thickness_simulation/tree/main/simulation_output): The simulation results.\n",
    "\n",
    "<a id='simulation-details'></a>\t\n",
    "## Simulation Details\n",
    "\n",
    "To run the code of this project, please install [Python 3](https://www.python.org/downloads/) and [Jupyter Notebook](https://jupyter.org/install.html). Please refer to Appendix D.1 of [Ye et al. (2022)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3702786) for more information about the simulation system. [The code](https://github.com/zikunye2/cold_start_to_improve_market_thickness_simulation/blob/main/cold_start_simulation.ipynb) contains the following four modules:\n",
    "\n",
    "* **Module I**: Two parallel simulations, one implementing the baseline ad delivery algorithm (i.e., the PID-controller driven bidding strategy) and the other implementing the Shadow Bidding with Learing and Dual Mirror Descent (SBL-DMD) Algorithm. See Section 4.1 and Appendix H.2 in [Ye et al. (2022)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3702786) for detailed introductions of the SBL-DMD and PID algorithms, respectively.\n",
    "* **Module II**: The Ad-side and UV-side experiment designs. See Section 5.1 and Appendix D.1 of [Ye et al. (2022)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3702786) for details.\n",
    "* **Module III**: The two-sided experiment design. See Section 5.1 and Appendix D.1 of [Ye et al. (2022)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3702786) for details.\n",
    "* **Module IV**: Resampling the outcomes for hypothesis testing.\n",
    "\n",
    "To evalute the performance of the estimators constructed from single- or two-sided experiments on an online advertising platform, we consider the following two metrics of interest in the simulation system (see Appendix D.1 of [Ye et al. (2022)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3702786) for details):\n",
    "\n",
    "* **Cold start success rate**, defined as the proportion of new ads successfully cold started by the algorithm deployed;\n",
    "* **Revenue**, total advertising revenue from new and mature ads on the platform.\n",
    "\n",
    "Through the simulation system, we replicate different field experiment designs to evalute the effectiveness of the SBL-DMD algorithm proposed by [Ye et al. (2022)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3702786). The [simulation results](https://github.com/zikunye2/cold_start_to_improve_market_thickness_simulation/tree/main/simulation_output) show that:\n",
    "\n",
    "* The **UV-side experiment design** significantly underestimates the cold start success rate, and significantly overestimates the revenue loss.\n",
    "* The **ad-side experiment design** significantly overestimates the cold start success rate.\n",
    "* The **two-side experiment** neither overestimates nor underestimates both performance metrics of interest.\n",
    "\n",
    "Interested readers are also free to change the hyper-parameters in [the code](https://github.com/zikunye2/cold_start_to_improve_market_thickness_simulation/blob/main/cold_start_simulation.ipynb) of the simulation system, such as (see [Ye et al. (2022)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3702786) for the definition and interpretation of each parameter):\n",
    "\n",
    "* The cold start success threshold.\n",
    "* The cold start reward of each ad.\n",
    "* The coefficients of the PID-controller.\n",
    "* The initialized dual variables and learning rate of the SBL-DMD algorithm.\n",
    "* The sampling rate of each experiment.\n",
    "* The auction mechanism (first-price or second-price). \n",
    "* The billing option (pay-by-impression, pay-by-click, pay-by-action, etc.)\n",
    "* The ground-truth CTR model.\n",
    "* The machine learning oracle for predicting CTR.\n",
    "\n",
    "## Reference\n",
    "Ye, Zikun, Dennis Zhang, Heng Zhang, Renyu Zhang, Xin Chen, and Zhiwei Xu. 2022. Cold Start to Improve Market Thickness on Online Advertising Platforms: Data-Driven Algorithms and Field Experiments. *Management Science*, forthcoming. Available at SSRN: https://ssrn.com/abstract=3702786 or http://dx.doi.org/10.2139/ssrn.3702786.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1e10c1",
   "metadata": {},
   "source": [
    "# Dictionary of datasets\n",
    "| Column        | Meaning                            |\n",
    "|---------------|------------------------------------|\n",
    "| imp_id        | impression ID                      |\n",
    "| unit_id       | ad ID                              |\n",
    "| unit_tag      | treatment condition of ad          |\n",
    "| exp_tag       | treatment condition of impression  |\n",
    "| p_date        | date                               |\n",
    "| p_hourmin     | hour                               |\n",
    "| pxtr          | predicted ctr*cvr                  |\n",
    "| retention_cnt | # of retention days                |\n",
    "| cvt_cnt       | # of conversions during cold start |\n",
    "| click         | # of clicks                        |\n",
    "| imp           | # of impressions                   |\n",
    "| auto_cpa_bid  | real-time bid                      |\n",
    "| target_bid    | bid set by advertisers             |\n",
    "| cost_total    | real cost of ads                   |\n",
    "| target_cost   | expected cost of ads               |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcecdaac",
   "metadata": {},
   "source": [
    "# Section 1: Figure 1 Ad retention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd5ffac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-30T20:15:06.373196Z",
     "start_time": "2022-07-30T20:15:06.361688Z"
    }
   },
   "source": [
    "## Figure 1 with observational data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03260b4f",
   "metadata": {},
   "source": [
    "Dataset [retention_data.csv'] contains observational data before the experiment. Each row records the basic information ('imp', 'click_cnt', 'cvr_cnt', 'target_cost', 'cost_total', 'target_bid'), aggregated at day level (p_date) of a specific ad (unit_id).\n",
    "Note: the code and data of matching and IV methods in paper Appendix are not given here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e5bd6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T01:54:45.407504Z",
     "start_time": "2022-07-31T01:54:44.304713Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('retention_data.csv')\n",
    "df = df[['unit_id', 'imp', 'click_cnt', 'cvr_cnt', 'target_cost',\n",
    "                                   'cost_total', 'target_bid', 'p_date']]\n",
    "df=df.dropna()\n",
    "max_cvr = 100\n",
    "ad_full_pct = np.zeros(max_cvr)\n",
    "ad_cvr_cnt = np.zeros(max_cvr)\n",
    "\n",
    "for unit_id, g in df.groupby(\"unit_id\"):\n",
    "    g_np = g.values\n",
    "    cvr_cnt = g_np[0,3]\n",
    "    for i in range(min(int(cvr_cnt+1), max_cvr)):\n",
    "        ad_cvr_cnt[i]+=1\n",
    "    if g.shape[0]>=14:#remain in more than 2 weeks\n",
    "        for i in range(min(int(cvr_cnt+1), max_cvr)):\n",
    "            ad_full_pct[i]+=1\n",
    "ad_full_pct = ad_full_pct/ad_cvr_cnt\n",
    "\n",
    "#linearly scaled\n",
    "figsize(6, 4)\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "plt.rcParams['savefig.dpi'] = 1200\n",
    "plt.rcParams['figure.dpi'] = 1200\n",
    "ax.yaxis.set_ticks_position('both')\n",
    "ax.xaxis.set_ticks_position('both')\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "plt.rc('font',family='Times New Roman')\n",
    "error_interval=1.26*np.sqrt(ad_full_pct*(1-ad_full_pct)/ad_cvr_cnt)\n",
    "min_value=min(ad_full_pct-error_interval)\n",
    "max_value=max(ad_full_pct+error_interval)\n",
    "plt.plot(range(max_cvr), (ad_full_pct-min_value)/(max_value-min_value), color='steelblue',linestyle='--',label='Average Retention Rate')\n",
    "plt.fill_between(range(max_cvr), (ad_full_pct-error_interval-min_value)/(max_value-min_value), \n",
    "\t(ad_full_pct+error_interval-min_value)/(max_value-min_value), color='lightskyblue', alpha=.3,label='95% Confidence Interval')\n",
    "plt.xlabel('Average Conversions per Day during the Cold-Start Period')\n",
    "plt.ylabel('Retention Rate of New Ads')\n",
    "plt.legend(loc=\"lower right\") \n",
    "ax.set_ylim(0,1)\n",
    "ax.set_xlim(0,100)\n",
    "plt.savefig('cold_start_reward.png', dpi=1200,bbox_inches='tight',pad_inches=0.0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5547e8e2",
   "metadata": {},
   "source": [
    "# Empirical analysis in Section 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d4168d",
   "metadata": {},
   "source": [
    "## Section 5 Randomization check of field experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e38f9d7",
   "metadata": {},
   "source": [
    "Dataset [randomization_check_data_block.csv] is used for randomization check and constains ad performance data before the experiments. Each row records the basic information ('target_cost','cost_total','cvt_cnt','auto_cpa_bid','target_bid','imp','click'), aggregated at day level ('p_date') of a specific ad ('unit_id') with the field ('unit_tag') indicating whether the ad is in the treatment group or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aa75c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T01:57:50.214949Z",
     "start_time": "2022-07-31T01:57:50.105775Z"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('randomization_check_data_block.csv')\n",
    "#column includes: 'unit_id','p_date','unit_tag','target_cost','cost_total','cvt_cnt','auto_cpa_bid','target_bid','imp','click'\n",
    "\n",
    "#check cold start reward and success rate\n",
    "df_exp_cvt=df[(df['unit_tag']=='exp')].groupby('unit_id').sum().reset_index()\n",
    "df_base_cvt=df[(df['unit_tag']=='base')].groupby('unit_id').sum().reset_index()\n",
    "\n",
    "df_exp_cvt=df_exp_cvt[df_exp_cvt['imp']>0][['unit_id','cvt_cnt']]\n",
    "df_base_cvt=df_base_cvt[df_base_cvt['imp']>0][['unit_id','cvt_cnt']]\n",
    "\n",
    "df_exp_bid=df[(df['unit_tag']=='exp')].groupby('unit_id')['target_bid'].mean().reset_index()\n",
    "df_base_bid=df[(df['unit_tag']=='base')].groupby('unit_id')['target_bid'].mean().reset_index()\n",
    "\n",
    "df_exp = pd.merge(df_exp_cvt, df_exp_bid, on='unit_id', how='left')\n",
    "df_base = pd.merge(df_base_cvt, df_base_bid, on='unit_id', how='left')\n",
    "\n",
    "df_exp['cold_start_rate']= df_exp['cvt_cnt'].apply(lambda x: 1 if x>=10 else 0)\n",
    "df_base['cold_start_rate']= df_base['cvt_cnt'].apply(lambda x: 1 if x>=10 else 0)\n",
    "\n",
    "df_exp['cold_start_reward']=np.minimum(df_exp['cvt_cnt'], 10)*df_exp['target_bid']*2/1000.0\n",
    "df_base['cold_start_reward']=np.minimum(df_base['cvt_cnt'], 10)*df_base['target_bid']*2/1000.0\n",
    "print('check cold start reward')\n",
    "print(ttest_ind(df_exp['cold_start_reward'],df_base['cold_start_reward']))\n",
    "print('exp', np.mean(df_exp['cold_start_reward']), np.std(df_exp['cold_start_reward']))\n",
    "print('base',np.mean(df_base['cold_start_reward']), np.std(df_base['cold_start_reward']))\n",
    "print('--------------------')\n",
    "print('check cold start success rate')\n",
    "print(ttest_ind(df_exp['cold_start_rate'],df_base['cold_start_rate']))\n",
    "print('exp',np.mean(df_exp['cold_start_rate']), np.std(df_exp['cold_start_rate']))\n",
    "print('base',np.mean(df_base['cold_start_rate']), np.std(df_base['cold_start_rate']))\n",
    "print('--------------------')\n",
    "\n",
    "\n",
    "#check # of impressions\n",
    "print('check # of impressions')\n",
    "df_exp=df[(df['unit_tag']=='exp')].groupby('unit_id').sum().reset_index()\n",
    "df_base=df[(df['unit_tag']=='base')].groupby('unit_id').sum().reset_index()\n",
    "df_exp=df_exp[df_exp['imp']>0]\n",
    "df_base=df_base[df_base['imp']>0]\n",
    "df_exp=df_exp['imp']\n",
    "df_base=df_base['imp']\n",
    "print('mean:',np.mean(df_exp),np.mean(df_base))\n",
    "print('std:',np.std(df_exp),np.std(df_base))\n",
    "print(ttest_ind(df_exp, df_base))\n",
    "print('--------------------')\n",
    "\n",
    "\n",
    "#check # of conversions\n",
    "print('check # of conversions')\n",
    "df_exp=df[(df['unit_tag']=='exp')].groupby('unit_id').sum().reset_index()\n",
    "df_base=df[(df['unit_tag']=='base')].groupby('unit_id').sum().reset_index()\n",
    "df_exp=df_exp[df_exp['imp']>0]\n",
    "df_base=df_base[df_base['imp']>0]\n",
    "df_exp=df_exp[df_exp['cvt_cnt']<1000]\n",
    "df_base=df_base[df_base['cvt_cnt']<1000]\n",
    "df_exp=df_exp['cvt_cnt']\n",
    "df_base=df_base['cvt_cnt']\n",
    "print('mean:',np.mean(df_exp),np.mean(df_base))\n",
    "print('std:',np.std(df_exp),np.std(df_base))\n",
    "print(ttest_ind(df_exp, df_base))\n",
    "print('--------------------')\n",
    "\n",
    "\n",
    "#check total revenue\n",
    "print('check total revenue')\n",
    "df_exp=df[(df['unit_tag']=='exp')].groupby('unit_id').sum().reset_index()\n",
    "df_base=df[(df['unit_tag']=='base')].groupby('unit_id').sum().reset_index()\n",
    "df_exp=df_exp[df_exp['imp']>0]\n",
    "df_base=df_base[df_base['imp']>0]\n",
    "df_exp=df_exp['cost_total']\n",
    "df_base=df_base['cost_total']\n",
    "print('mean:',np.mean(df_exp),np.mean(df_base))\n",
    "print('std:',np.std(df_exp),np.std(df_base))\n",
    "print(ttest_ind(df_exp, df_base))\n",
    "print('--------------------')\n",
    "\n",
    "\n",
    "#check # of ads\n",
    "print('check # of ads')\n",
    "df_exp=df[(df['unit_tag']=='exp')].groupby('unit_id').sum().reset_index()\n",
    "df_base=df[(df['unit_tag']=='base')].groupby('unit_id').sum().reset_index()\n",
    "df_exp=df_exp[df_exp['imp']>0]\n",
    "df_base=df_base[df_base['imp']>0]\n",
    "df_exp=df_exp['click']\n",
    "df_base=df_base['click']\n",
    "print('mean:',np.mean(df_exp),np.mean(df_base))\n",
    "print('std:',np.std(df_exp),np.std(df_base))\n",
    "print(ttest_ind(df_exp, df_base))\n",
    "print('--------------------')\n",
    "\n",
    "\n",
    "#check CTR CVR\n",
    "df_exp=df[(df['unit_tag']=='exp')].groupby('unit_id').sum().reset_index()\n",
    "df_base=df[(df['unit_tag']=='base')].groupby('unit_id').sum().reset_index()\n",
    "df_exp=df_exp[df_exp['imp']>0]\n",
    "df_base=df_base[df_base['imp']>0]\n",
    "df_exp=df_exp[df_exp['click']>0]\n",
    "df_base=df_base[df_base['click']>0]\n",
    "\n",
    "df_exp['ctr']=df_exp['click']/df_exp['imp']\n",
    "df_exp['cvr']=df_exp['cvt_cnt']/df_exp['click']\n",
    "\n",
    "df_base['ctr']=df_base['click']/df_base['imp']\n",
    "df_base['cvr']=df_base['cvt_cnt']/df_base['click']\n",
    "\n",
    "df_exp=df_exp[df_exp['ctr']<1]\n",
    "df_base=df_base[df_base['ctr']<1]\n",
    "df_exp=df_exp[df_exp['cvr']<1]\n",
    "df_base=df_base[df_base['cvr']<1]\n",
    "\n",
    "print('CTR check:')\n",
    "print('mean:',np.mean(df_exp['ctr']),np.mean(df_base['ctr']))\n",
    "print('std:',np.std(df_exp['ctr']),np.std(df_base['ctr']))\n",
    "print(ttest_ind(df_exp['ctr'], df_base['ctr']))\n",
    "print('--------------------')\n",
    "\n",
    "print('CVR check:')\n",
    "print('mean:',np.mean(df_exp['cvr']),np.mean(df_base['cvr']))\n",
    "print('std:',np.std(df_exp['cvr']),np.std(df_base['cvr']))\n",
    "print(ttest_ind(df_exp['cvr'], df_base['cvr']))\n",
    "print('--------------------')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a01a594",
   "metadata": {},
   "source": [
    "# Empirical analysis in Section 6 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147872ba",
   "metadata": {},
   "source": [
    "## Section 6.1 Short-Term Performance of Our oSBL Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96a4ea3",
   "metadata": {},
   "source": [
    "Dataset [exp_short_term_results.csv] contains the ad performance data during the experiment. Each row records the basic performance information aggregated at hour level ('p_date','p_hourmin') of a specific ad ('unit_id') with assigned conditions ('exp_tag','unit_tag').\n",
    "\n",
    "Dataset [exp_cost_results.csv] contains the revenue performance aggregated at hour level during the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8b8147",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T02:26:55.223489Z",
     "start_time": "2022-07-31T02:26:52.058696Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('exp_short_term_results.csv')#aggregate at ad*day_hour level with different experiment conditions\n",
    "df=df[['unit_id','p_date','p_hourmin','exp_tag','unit_tag','target_cost','cost_total','cvt_cnt','auto_cpa_bid','target_bid','imp','click']]\n",
    "\n",
    "#Panel A: Effects on the Cold Start at the Ad Level\n",
    "print('===================================================')\n",
    "print('Panel A')\n",
    "#impressions\n",
    "df_exp=df[(df['exp_tag']=='exp1') & (df['unit_tag']=='exp')].groupby('unit_id').sum().reset_index()\n",
    "df_base=df[(df['exp_tag']=='base1') & (df['unit_tag']=='ctrl')].groupby('unit_id').sum().reset_index()\n",
    "df_exp=df_exp[df_exp['imp']>0]\n",
    "df_base=df_base[df_base['imp']>0]\n",
    "df_exp=df_exp['imp']\n",
    "df_base=df_base['imp']\n",
    "print('Check impressions:')\n",
    "print('mean of exp and base groups:',np.mean(df_exp), np.mean(df_base))\n",
    "print('std:',np.std(df_exp),np.std(df_base))\n",
    "print('ttest', ttest_ind(df_exp, df_base))\n",
    "print('----------------------------------------------------')\n",
    "\n",
    "#clicks\n",
    "df_exp=df[(df['exp_tag']=='exp1') & (df['unit_tag']=='exp')].groupby('unit_id').sum().reset_index()\n",
    "df_base=df[(df['exp_tag']=='base1') & (df['unit_tag']=='ctrl')].groupby('unit_id').sum().reset_index()\n",
    "df_exp=df_exp[df_exp['imp']>0]\n",
    "df_base=df_base[df_base['imp']>0]\n",
    "df_exp=df_exp['click']\n",
    "df_base=df_base['click']\n",
    "print('Check clicks:')\n",
    "print('mean of exp and base groups:',np.mean(df_exp),np.mean(df_base))\n",
    "print('std:',np.std(df_exp),np.std(df_base))\n",
    "print('ttest', ttest_ind(df_exp, df_base))\n",
    "print('----------------------------------------------------')\n",
    "\n",
    "\n",
    "#conversions\n",
    "print('Check conversions:')\n",
    "df_exp=df[(df['exp_tag']=='exp1') & (df['unit_tag']=='exp')].groupby('unit_id').sum().reset_index()\n",
    "df_base=df[(df['exp_tag']=='base1') & (df['unit_tag']=='ctrl')].groupby('unit_id').sum().reset_index()\n",
    "df_exp=df_exp[df_exp['imp']>0]\n",
    "df_base=df_base[df_base['imp']>0]\n",
    "df_exp=df_exp['cvt_cnt']\n",
    "df_base=df_base['cvt_cnt']\n",
    "print('mean of exp and base groups:',np.mean(df_exp),np.mean(df_base))\n",
    "print('std:',np.std(df_exp),np.std(df_base))\n",
    "print('ttest', ttest_ind(df_exp, df_base))\n",
    "print('----------------------------------------------------')\n",
    "\n",
    "\n",
    "#bid price\n",
    "df_exp=df[(df['exp_tag']=='exp1') & (df['unit_tag']=='exp')].groupby('unit_id').mean().reset_index()\n",
    "df_base=df[(df['exp_tag']=='base1') & (df['unit_tag']=='ctrl')].groupby('unit_id').mean().reset_index()\n",
    "df_exp=df_exp[df_exp['imp']>0]\n",
    "df_base=df_base[df_base['imp']>0]\n",
    "df_exp=df_exp['target_bid']\n",
    "df_base=df_base['target_bid']\n",
    "print('Check bid prices:')\n",
    "print('mean of exp and base groups:',np.mean(df_exp),np.mean(df_base))\n",
    "print('std:',np.std(df_exp),np.std(df_base))\n",
    "print('ttest', ttest_ind(df_exp, df_base))\n",
    "print('----------------------------------------------------')\n",
    "\n",
    "\n",
    "#cold start success rate\n",
    "target=10\n",
    "bound=2000000\n",
    "B11_cvt = df[(df['exp_tag']=='exp1') & (df['unit_tag']=='exp')].groupby('unit_id').sum().reset_index()\n",
    "B22_cvt = df[(df['exp_tag']=='base1') & (df['unit_tag']=='ctrl')].groupby('unit_id').sum().reset_index()\n",
    "B11_cvt=B11_cvt[B11_cvt['imp']>0]\n",
    "B22_cvt=B22_cvt[B22_cvt['imp']>0]\n",
    "B11_cvt=B11_cvt['cvt_cnt']\n",
    "B22_cvt=B22_cvt['cvt_cnt']\n",
    "B11=0\n",
    "B22=0\n",
    "for i in list(B11_cvt):\n",
    "    if i>=target and i<=bound:\n",
    "        B11+=1\n",
    "for i in list(B22_cvt):\n",
    "    if i>=target and i<=bound:\n",
    "        B22+=1\n",
    "B11=B11/B11_cvt.count()\n",
    "B22=B22/B22_cvt.count()\n",
    "print('Check cold start success rate')\n",
    "print('ttest', ttest_ind(B11_cvt, B22_cvt))\n",
    "print('----------------------------------------------------')\n",
    "\n",
    "#Panel B: Effects of the Algorithm on Short-Term Revenue and the Objective Value\n",
    "print('===================================================')\n",
    "print('Panel B: Effects of the Algorithm on Short-Term Revenue and the Objective Value')\n",
    "df_cost = pd.read_csv('exp_cost_results.csv')\n",
    "df_cost=df_cost.sort_values(by=['p_date','p_hourmin'])\n",
    "dates=[20200523,20200524,20200525,20200526,20200527,20200528,20200529]\n",
    "x= [datetime.datetime.strptime(str(d), '%Y%m%d').date() for d in dates]\n",
    "plt.gcf().autofmt_xdate()\n",
    "fig=plt.figure(figsize=(15,5))\n",
    "ax1=fig.add_subplot(1,1,1) \n",
    "date1_1 = dt.datetime(2020,5, 23, 0)\n",
    "date1_2 = dt.datetime(2020, 5, 29, 20)\n",
    "delta1 = dt.timedelta(hours=1)\n",
    "dates1 = matplotlib.dates.drange(date1_1, date1_2, delta1)\n",
    "y1 = np.random.rand(len(dates1))\n",
    "dateFmt = matplotlib.dates.DateFormatter('%Y-%m-%d')\n",
    "ax1.xaxis.set_major_formatter(dateFmt)\n",
    "daysLoc = matplotlib.dates.DayLocator()\n",
    "hoursLoc = matplotlib.dates.HourLocator(interval=6)\n",
    "ax1.xaxis.set_major_locator(daysLoc)\n",
    "ax1.xaxis.set_minor_locator(hoursLoc)\n",
    "ax1.plot(dates1[0:164],df_cost[df_cost['exp_tag']=='base1']['cost_total'].reset_index()['cost_total'], label='base', color='b',linestyle='-.')\n",
    "ax1.plot(dates1[0:164],df_cost[df_cost['exp_tag']=='exp1']['cost_total'].reset_index()['cost_total'],label='exp', color='r',linestyle=':')\n",
    "plt.xlabel('hour')\n",
    "plt.ylabel('cost')\n",
    "plt.title('Total revenue by groups')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "df_exp_cvt=df[(df['exp_tag']=='exp1') & (df['unit_tag']=='exp')].groupby('unit_id').sum().reset_index()\n",
    "df_base_cvt=df[(df['exp_tag']=='base1') & (df['unit_tag']=='ctrl')].groupby('unit_id').sum().reset_index()\n",
    "df_exp_cvt=df_exp_cvt[df_exp_cvt['imp']>0][['unit_id','cvt_cnt','imp','click']]\n",
    "df_base_cvt=df_base_cvt[df_base_cvt['imp']>0][['unit_id','cvt_cnt','imp','click']]\n",
    "df_exp_bid=df[(df['exp_tag']=='exp1') & (df['unit_tag']=='exp')].groupby('unit_id')['target_bid'].mean().reset_index()\n",
    "df_base_bid=df[(df['exp_tag']=='base1') & (df['unit_tag']=='ctrl')].groupby('unit_id')['target_bid'].mean().reset_index()\n",
    "df_exp = pd.merge(df_exp_cvt, df_exp_bid, on='unit_id', how='left')\n",
    "df_base = pd.merge(df_base_cvt, df_base_bid, on='unit_id', how='left')\n",
    "\n",
    "df_exp['cold_start_rate']= df_exp['cvt_cnt'].apply(lambda x: 1 if x>=10 else 0)\n",
    "df_base['cold_start_rate']= df_base['cvt_cnt'].apply(lambda x: 1 if x>=10 else 0)\n",
    "\n",
    "df_exp['cold_start_reward']=np.minimum(df_exp['cvt_cnt'], 10)*df_exp['target_bid']*2/1000.0\n",
    "df_base['cold_start_reward']=np.minimum(df_base['cvt_cnt'], 10)*df_base['target_bid']*2/1000.0\n",
    "\n",
    "print(df_exp['cold_start_reward'].sum(), df_exp.groupby('unit_id').unit_id.nunique().count())\n",
    "print(df_base['cold_start_reward'].sum(), df_base.groupby('unit_id').unit_id.nunique().count())\n",
    "print('------------revenue--------------')\n",
    "print('Note: current code applies t-test at hour granularity, our paper report t-test at impression granularity')\n",
    "rev_base = df_cost[df_cost['exp_tag']=='base1']['cost_total'].reset_index()['cost_total'].to_numpy()\n",
    "rev_exp = df_cost[df_cost['exp_tag']=='exp1']['cost_total'].reset_index()['cost_total'].to_numpy()\n",
    "print('ttest:', ttest_ind(rev_exp, rev_base))\n",
    "print('exp', np.mean(df_exp['cold_start_reward']), np.std(df_exp['cold_start_reward']))\n",
    "print('base',np.mean(df_base['cold_start_reward']), np.std(df_base['cold_start_reward']))\n",
    "print('------------cold start reward--------------')\n",
    "print('ttest:', ttest_ind(df_exp['cold_start_reward'],df_base['cold_start_reward']))\n",
    "print('exp', np.mean(df_exp['cold_start_reward']), np.std(df_exp['cold_start_reward']))\n",
    "print('base',np.mean(df_base['cold_start_reward']), np.std(df_base['cold_start_reward']))\n",
    "print('------------cold start rate--------------')\n",
    "print('ttest:', ttest_ind(df_exp['cold_start_rate'],df_base['cold_start_rate']))\n",
    "print('exp',np.mean(df_exp['cold_start_rate']), np.std(df_exp['cold_start_rate']))\n",
    "print('base',np.mean(df_base['cold_start_rate']), np.std(df_base['cold_start_rate']))\n",
    "\n",
    "##Panel C: Effects of the Algorithm on Advertiser Costs\n",
    "print('===================================================')\n",
    "print('Panel C: Effects of the Algorithm on Advertiser Costs')\n",
    "level_1_exp=[]\n",
    "level_1_base=[]\n",
    "level_2_exp=[]\n",
    "level_2_base=[]\n",
    "level_3_exp=[]\n",
    "level_3_base=[]\n",
    "df_tempt=df.dropna(axis=0,how='any')\n",
    "for time_, g in df_tempt.groupby(['p_date']):\n",
    "    exp_cvt_cost = g[(g['exp_tag']=='exp1') & (g['unit_tag']=='exp')].groupby('unit_id').sum()\n",
    "    ctrl_cvt_cost = g[(g['exp_tag']=='base1') & (g['unit_tag']=='ctrl')].groupby('unit_id').sum()\n",
    "    exp_cvt_cost = exp_cvt_cost[(exp_cvt_cost['cost_total']>0) & (exp_cvt_cost['target_cost']>0)]\n",
    "    ctrl_cvt_cost = ctrl_cvt_cost[(ctrl_cvt_cost['cost_total']>0) & (ctrl_cvt_cost['target_cost']>0)]\n",
    "    exp_cvt_cost['cost_ratio'] = exp_cvt_cost['cost_total']/exp_cvt_cost['target_cost']\n",
    "    ctrl_cvt_cost['cost_ratio'] = ctrl_cvt_cost['cost_total']/ctrl_cvt_cost['target_cost']\n",
    "    #print('+-30%')\n",
    "    level_1_exp.append(exp_cvt_cost[(exp_cvt_cost['cost_ratio']<1.3) & (exp_cvt_cost['cost_ratio']>0.7)]['cost_ratio'].count()/exp_cvt_cost['cost_ratio'].count())\n",
    "    level_1_base.append(ctrl_cvt_cost[(ctrl_cvt_cost['cost_ratio']<1.3) & (ctrl_cvt_cost['cost_ratio']>0.7)]['cost_ratio'].count()/ctrl_cvt_cost['cost_ratio'].count())\n",
    "    \n",
    "    #30%~100%\n",
    "    #print('30%~100%')\n",
    "    level_2_exp.append(exp_cvt_cost[(exp_cvt_cost['cost_ratio']>1.3) & (exp_cvt_cost['cost_ratio']<2)]['cost_ratio'].count()/exp_cvt_cost['cost_ratio'].count())\n",
    "    level_2_base.append(ctrl_cvt_cost[(ctrl_cvt_cost['cost_ratio']>1.3) & (ctrl_cvt_cost['cost_ratio']<2)]['cost_ratio'].count()/ctrl_cvt_cost['cost_ratio'].count())\n",
    "    \n",
    "    #>100%\n",
    "    #print('>100%')\n",
    "    level_3_exp.append(exp_cvt_cost[(exp_cvt_cost['cost_ratio']>2)]['cost_ratio'].count()/exp_cvt_cost['cost_ratio'].count())\n",
    "    level_3_base.append(ctrl_cvt_cost[(ctrl_cvt_cost['cost_ratio']>2)]['cost_ratio'].count()/ctrl_cvt_cost['cost_ratio'].count())\n",
    "level_1_exp = np.array(level_1_exp)\n",
    "level_1_base = np.array(level_1_base)\n",
    "level_2_exp = np.array(level_1_exp)\n",
    "level_2_base = np.array(level_1_base)\n",
    "level_3_exp = np.array(level_1_exp)\n",
    "level_3_base = np.array(level_1_base)\n",
    "print('ttest at +-30%:', ttest_ind(level_1_exp,level_1_base))\n",
    "print('ttest at 30%~100%:', ttest_ind(level_2_exp,level_2_base))\n",
    "print('ttest at >100%:', ttest_ind(level_3_exp,level_3_base))\n",
    "print('===================================================')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed279512",
   "metadata": {},
   "source": [
    "## Section 6.2 Long-term effects of oSBL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349ad837",
   "metadata": {},
   "source": [
    "Dataset [oSBL_ad_level_long_term_results.csv] contains post-experiment data for around 3 months. Each row records the basic performance information aggregated at day level ('p_date') of a specific ad ('unit_id') with assigned conditions ('unit_tag')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4c1c53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T02:29:04.157176Z",
     "start_time": "2022-07-31T02:29:03.951806Z"
    }
   },
   "outputs": [],
   "source": [
    "#Figure 6 \n",
    "#this code cannot run on the given sample dataset [oSBL_ad_level_long_term_results.csv] because \n",
    "#the sample dataset does not cover all post-experiment periods from 5/30/2020 to 8/21/2020. \n",
    "#Thus a dimension mismatch bug in line 29-30.\n",
    "\n",
    "df_sbl_long = pd.read_csv('oSBL_ad_level_long_term_results.csv')#aggregate at day*ad level\n",
    "df_sbl_long = df_sbl_long[['p_date','unit_id','unit_tag','target_cost','cost_total','cvt_cnt','auto_cpa_bid','target_bid','imp','click']]\n",
    "df_sbl_long['unit_tag']= df_sbl_long['unit_tag'].apply(lambda x: 'exp' if x=='exp' else 'ctrl')\n",
    "\n",
    "df_sbl_long_2 = df_sbl_long.copy()\n",
    "figsize(6, 4)\n",
    "plt.rcParams['savefig.dpi'] = 300 \n",
    "plt.rcParams['figure.dpi'] = 300 \n",
    "df_sbl_long_cnt=df_sbl_long_2.groupby(['p_date','unit_tag']).unit_id.nunique().reset_index().sort_values(by=['p_date'])\n",
    "plt.gcf().autofmt_xdate() \n",
    "fig=plt.figure(figsize=(15,5))\n",
    "ax1=fig.add_subplot(1,1,1) \n",
    "date1_1 = dt.datetime(2020,5, 30, 0)\n",
    "date1_2 = dt.datetime(2020,8, 21, 0)\n",
    "delta1 = dt.timedelta(days=1)\n",
    "dates1 = matplotlib.dates.drange(date1_1, date1_2, delta1)\n",
    "y1 = np.random.rand(len(dates1))\n",
    "dateFmt = matplotlib.dates.DateFormatter('%Y-%m-%d')\n",
    "ax1.xaxis.set_major_formatter(dateFmt)\n",
    " \n",
    "daysLoc = matplotlib.dates.DayLocator(interval=7)\n",
    "ax1.xaxis.set_major_locator(daysLoc)\n",
    "\n",
    "ax1.plot(dates1[0:83],df_sbl_long_cnt[df_sbl_long_cnt['unit_tag']=='ctrl']['unit_id'], label='Control', color='b',linestyle='-.')\n",
    "ax1.plot(dates1[0:83],df_sbl_long_cnt[df_sbl_long_cnt['unit_tag']=='exp']['unit_id'], label='Treatment', color='r',linestyle=':')\n",
    "\n",
    "plt.xlabel('date')\n",
    "plt.ylabel('Market Thickness of Experimental Ads')\n",
    "plt.ylim([0,0.6])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig.savefig('market_thickness.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f1cb5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-31T02:28:54.313620Z",
     "start_time": "2022-07-31T02:28:54.211019Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sbl_long = pd.read_csv('oSBL_ad_level_long_term_results.csv')#aggregate at day*ad level\n",
    "df_sbl_long = df_sbl_long[['p_date','unit_id','unit_tag','target_cost','cost_total','cvt_cnt','auto_cpa_bid','target_bid','imp','click']]\n",
    "df_sbl_long['unit_tag']= df_sbl_long['unit_tag'].apply(lambda x: 'exp' if x=='exp' else 'ctrl')\n",
    "df_sbl_long_2 = df_sbl_long.copy()\n",
    "df_test = df_sbl_long_2.groupby(['unit_id','unit_tag']).sum().reset_index()\n",
    "\n",
    "rescale_ = 1 #true rescale number is not revealed in the code\n",
    "limits = [0, 0.9]#winsorization limit\n",
    "df_test['imp']=rescale_*df_test['imp']\n",
    "df_test['cost_total']=rescale_*df_test['cost_total']\n",
    "df_test['target_cost']=rescale_*df_test['target_cost']\n",
    "\n",
    "print('Post-exp lifetime impressions')\n",
    "print(stats.ttest_ind(df_test[df_test['unit_tag']=='exp']['imp'],\n",
    "                df_test[df_test['unit_tag']=='ctrl']['imp']))\n",
    "print('exp=',df_test[df_test['unit_tag']=='exp']['imp'].mean())\n",
    "print('ctrl=',df_test[df_test['unit_tag']=='ctrl']['imp'].mean())\n",
    "print('effect= ', df_test[df_test['unit_tag']=='exp']['imp'].mean()/df_test[df_test['unit_tag']=='ctrl']['imp'].mean()-1)\n",
    "\n",
    "print('std exp=',df_test[df_test['unit_tag']=='exp']['imp'].std())\n",
    "print('std ctrl=',df_test[df_test['unit_tag']=='ctrl']['imp'].std())\n",
    "print('==================================================')\n",
    "\n",
    "print('Post-exp lifetime log-impressions')\n",
    "print(stats.ttest_ind(np.log(df_test[df_test['unit_tag']=='exp']['imp']),\n",
    "                np.log(df_test[df_test['unit_tag']=='ctrl']['imp'])))\n",
    "print('exp=',np.log(df_test[df_test['unit_tag']=='exp']['imp']).mean())\n",
    "print('ctrl=',np.log(df_test[df_test['unit_tag']=='ctrl']['imp']).mean())\n",
    "print('effect= ',np.log(df_test[df_test['unit_tag']=='exp']['imp']).mean()/np.log(df_test[df_test['unit_tag']=='ctrl']['imp']).mean()-1)\n",
    "\n",
    "print('std exp=',np.log(df_test[df_test['unit_tag']=='exp']['imp']).std())\n",
    "print('std ctrl=',np.log(df_test[df_test['unit_tag']=='ctrl']['imp']).std())\n",
    "\n",
    "\n",
    "print('==================================================')\n",
    "\n",
    "print('Post-exp lifetime winsorize-impressions')\n",
    "print(stats.ttest_ind(winsorize(df_test[df_test['unit_tag']=='exp']['imp'], limits),\n",
    "                winsorize(df_test[df_test['unit_tag']=='ctrl']['imp'], limits)))\n",
    "print('exp=',winsorize(df_test[df_test['unit_tag']=='exp']['imp'], limits).mean())\n",
    "print('ctrl=',winsorize(df_test[df_test['unit_tag']=='ctrl']['imp'],limits).mean())\n",
    "print('effect= ',winsorize(df_test[df_test['unit_tag']=='exp']['imp'], limits).mean()/winsorize(df_test[df_test['unit_tag']=='ctrl']['imp'],limits).mean()-1)\n",
    "\n",
    "print('std exp=',winsorize(df_test[df_test['unit_tag']=='exp']['imp'],limits).std())\n",
    "print('std ctrl=',winsorize(df_test[df_test['unit_tag']=='ctrl']['imp'],limits).std())\n",
    "print('==================================================')\n",
    "\n",
    "df_test['cost_total']=df_test['cost_total']+1\n",
    "df_test['target_cost']=df_test['target_cost']+1\n",
    "print('Post-exp lifetime cost_total')\n",
    "print(stats.ttest_ind(df_test[df_test['unit_tag']=='exp']['cost_total'],\n",
    "                df_test[df_test['unit_tag']=='ctrl']['cost_total']))\n",
    "print('exp=',df_test[df_test['unit_tag']=='exp']['cost_total'].mean())\n",
    "print('ctrl=',df_test[df_test['unit_tag']=='ctrl']['cost_total'].mean())\n",
    "print('effect= ', df_test[df_test['unit_tag']=='exp']['cost_total'].mean()/df_test[df_test['unit_tag']=='ctrl']['cost_total'].mean()-1)\n",
    "print('std exp=',df_test[df_test['unit_tag']=='exp']['cost_total'].std())\n",
    "print('std ctrl=',df_test[df_test['unit_tag']=='ctrl']['cost_total'].std())\n",
    "print('==================================================')\n",
    "\n",
    "\n",
    "\n",
    "print('Post-exp lifetime log cost_total')\n",
    "print(stats.ttest_ind(np.log(df_test[df_test['unit_tag']=='exp']['cost_total']),\n",
    "                np.log(df_test[df_test['unit_tag']=='ctrl']['cost_total'])))\n",
    "print('exp=',np.log(df_test[df_test['unit_tag']=='exp']['cost_total']).mean())\n",
    "print('ctrl=',np.log(df_test[df_test['unit_tag']=='ctrl']['cost_total']).mean())\n",
    "print('effect= ',np.log(df_test[df_test['unit_tag']=='exp']['cost_total']).mean()/np.log(df_test[df_test['unit_tag']=='ctrl']['cost_total']).mean()-1)\n",
    "\n",
    "print('std exp=',np.log(df_test[df_test['unit_tag']=='exp']['cost_total']).std())\n",
    "print('std ctrl=',np.log(df_test[df_test['unit_tag']=='ctrl']['cost_total']).std())\n",
    "print('==================================================')\n",
    "\n",
    "print('Post-exp lifetime lifetime winsorize cost_total')\n",
    "print(stats.ttest_ind(winsorize(df_test[df_test['unit_tag']=='exp']['cost_total'], limits),\n",
    "                winsorize(df_test[df_test['unit_tag']=='ctrl']['cost_total'], limits)))\n",
    "print('exp=',winsorize(df_test[df_test['unit_tag']=='exp']['cost_total'], limits).mean())\n",
    "print('ctrl=',winsorize(df_test[df_test['unit_tag']=='ctrl']['cost_total'],limits).mean())\n",
    "print('effect= ',winsorize(df_test[df_test['unit_tag']=='exp']['cost_total'], limits).mean()/winsorize(df_test[df_test['unit_tag']=='ctrl']['cost_total'],limits).mean()-1)\n",
    "\n",
    "print('std exp=',winsorize(df_test[df_test['unit_tag']=='exp']['cost_total'],limits).std())\n",
    "print('std ctrl=',winsorize(df_test[df_test['unit_tag']=='ctrl']['cost_total'],limits).std())\n",
    "print('==================================================')\n",
    "\n",
    "print('Post-exp lifetime target_cost')\n",
    "print(stats.ttest_ind(df_test[df_test['unit_tag']=='exp']['target_cost'],\n",
    "                df_test[df_test['unit_tag']=='ctrl']['target_cost']))\n",
    "print('exp=',df_test[df_test['unit_tag']=='exp']['target_cost'].mean())\n",
    "print('ctrl=',df_test[df_test['unit_tag']=='ctrl']['target_cost'].mean())\n",
    "print('std exp=',df_test[df_test['unit_tag']=='exp']['target_cost'].std())\n",
    "print('std ctrl=',df_test[df_test['unit_tag']=='ctrl']['target_cost'].std())\n",
    "print('==================================================')\n",
    "\n",
    "print('Post-exp lifetime log target_cost')\n",
    "print(stats.ttest_ind(np.log(df_test[df_test['unit_tag']=='exp']['target_cost']),\n",
    "                np.log(df_test[df_test['unit_tag']=='ctrl']['target_cost'])))\n",
    "print('exp=',np.log(df_test[df_test['unit_tag']=='exp']['target_cost']).mean())\n",
    "print('ctrl=',np.log(df_test[df_test['unit_tag']=='ctrl']['target_cost']).mean())\n",
    "print('std exp=',np.log(df_test[df_test['unit_tag']=='exp']['target_cost']).std())\n",
    "print('std ctrl=',np.log(df_test[df_test['unit_tag']=='ctrl']['target_cost']).std())\n",
    "print('==================================================')\n",
    "\n",
    "print('Post-exp lifetime winsorize target_cost')\n",
    "print(stats.ttest_ind(winsorize(df_test[df_test['unit_tag']=='exp']['target_cost'], limits),\n",
    "                winsorize(df_test[df_test['unit_tag']=='ctrl']['target_cost'], limits)))\n",
    "print('exp=',winsorize(df_test[df_test['unit_tag']=='exp']['target_cost'], limits).mean())\n",
    "print('ctrl=',winsorize(df_test[df_test['unit_tag']=='ctrl']['target_cost'],limits).mean())\n",
    "print('std exp=',winsorize(df_test[df_test['unit_tag']=='exp']['target_cost'],limits).std())\n",
    "print('std ctrl=',winsorize(df_test[df_test['unit_tag']=='ctrl']['target_cost'],limits).std())\n",
    "print('==================================================')\n",
    "\n",
    "df_test['imp']=df_test['imp']+1\n",
    "df_test['ctr']=df_test['click']/df_test['imp']\n",
    "df_test['ctr']=rescale_*df_test['ctr']\n",
    "\n",
    "\n",
    "print('Post-exp average CTR')\n",
    "print(stats.ttest_ind(df_test[df_test['unit_tag']=='exp']['ctr'],\n",
    "                df_test[df_test['unit_tag']=='ctrl']['ctr']))\n",
    "print('exp=',df_test[df_test['unit_tag']=='exp']['ctr'].mean())\n",
    "print('ctrl=',df_test[df_test['unit_tag']=='ctrl']['ctr'].mean())\n",
    "print('effect= ', df_test[df_test['unit_tag']=='exp']['ctr'].mean()/df_test[df_test['unit_tag']=='ctrl']['ctr'].mean()-1)\n",
    "\n",
    "print('std exp=',df_test[df_test['unit_tag']=='exp']['ctr'].std())\n",
    "print('std ctrl=',df_test[df_test['unit_tag']=='ctrl']['ctr'].std())\n",
    "print('==================================================')\n",
    "\n",
    "df_test['click']=df_test['click']+1\n",
    "df_test['cvr']=df_test['cvt_cnt']/df_test['click']\n",
    "df_test=df_test[df_test['cvr']<1]\n",
    "df_test['cvr']=rescale_*df_test['cvr']\n",
    "\n",
    "print('Post-exp average CVR')\n",
    "print(stats.ttest_ind(df_test[df_test['unit_tag']=='exp']['cvr'],\n",
    "                df_test[df_test['unit_tag']=='ctrl']['cvr']))\n",
    "print('exp=',df_test[df_test['unit_tag']=='exp']['cvr'].mean())\n",
    "print('ctrl=',df_test[df_test['unit_tag']=='ctrl']['cvr'].mean())\n",
    "print('std exp=',df_test[df_test['unit_tag']=='exp']['cvr'].std())\n",
    "print('std ctrl=',df_test[df_test['unit_tag']=='ctrl']['cvr'].std())\n",
    "print('==================================================')\n",
    "\n",
    "\n",
    "df_test = df_sbl_long_2.groupby(['unit_id','unit_tag']).mean().reset_index()\n",
    "df_test['target_bid']=rescale_*df_test['target_bid']\n",
    "df_test['auto_cpa_bid']=rescale_*df_test['auto_cpa_bid']\n",
    "\n",
    "print('Post-exp average target_bid')\n",
    "print(stats.ttest_ind(df_test[df_test['unit_tag']=='exp']['target_bid'],\n",
    "                df_test[df_test['unit_tag']=='ctrl']['target_bid']))\n",
    "print('exp=',df_test[df_test['unit_tag']=='exp']['target_bid'].mean())\n",
    "print('ctrl=',df_test[df_test['unit_tag']=='ctrl']['target_bid'].mean())\n",
    "print('std exp=',df_test[df_test['unit_tag']=='exp']['target_bid'].std())\n",
    "print('std ctrl=',df_test[df_test['unit_tag']=='ctrl']['target_bid'].std())\n",
    "print('==================================================')\n",
    "\n",
    "print('Post-exp average auto_cpa_bid')\n",
    "print(stats.ttest_ind(df_test[df_test['unit_tag']=='exp']['auto_cpa_bid'],\n",
    "                df_test[df_test['unit_tag']=='ctrl']['auto_cpa_bid']))\n",
    "print('exp=',df_test[df_test['unit_tag']=='exp']['auto_cpa_bid'].mean())\n",
    "print('ctrl=',df_test[df_test['unit_tag']=='ctrl']['auto_cpa_bid'].mean())\n",
    "print('effect= ', df_test[df_test['unit_tag']=='exp']['auto_cpa_bid'].mean()/df_test[df_test['unit_tag']=='ctrl']['auto_cpa_bid'].mean()-1)\n",
    "\n",
    "print('std exp=',df_test[df_test['unit_tag']=='exp']['auto_cpa_bid'].std())\n",
    "print('std ctrl=',df_test[df_test['unit_tag']=='ctrl']['auto_cpa_bid'].std())\n",
    "print('==================================================')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910ab732",
   "metadata": {},
   "source": [
    "## Section 6.3 Global Treatment Effect of Our oSBL Algorithm on Advertising Revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fdbbe0",
   "metadata": {},
   "source": [
    "Each row in data [auction_level_data.csv] is one record of the auction: for a specific auction ('imp_id') happened at date ('p_date'), one ad ('unit_id') join the auction with key information including predicted CTRxCVR ('pxtr'), bid price ('auto_cpa_bid') and new ad indicator ('is_new')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c0a584",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-30T22:05:00.996292Z",
     "start_time": "2022-07-30T22:04:20.469263Z"
    }
   },
   "outputs": [],
   "source": [
    "df_auction_long = pd.read_csv('auction_level_data.csv')\n",
    "df_auction_long = df_auction_long[['imp_id','p_date','unit_id','pxtr','auto_cpa_bid','is_new']]\n",
    "df_auction_long['cpm'] =  df_auction_long['pxtr']*df_auction_long['auto_cpa_bid']\n",
    "df_new_bonus = pd.DataFrame(columns=['p_date', 'unit_id'])\n",
    "for i, g in df_auction_long.groupby('p_date'):\n",
    "    g_ = g.sort_values(by=['cpm'], ascending=False, kind='mergesort').drop_duplicates('imp_id')\n",
    "    g_ = g_[g_['is_new']==1].groupby(['p_date','unit_id'])['pxtr'].sum().reset_index()\n",
    "    g_ = g_.sort_values(by=['pxtr'], ascending=False, kind='mergesort')[['p_date', 'unit_id']]\n",
    "    num_new_ads = g[g['is_new']==1].unit_id.nunique()\n",
    "    df_new_bonus = pd.concat([df_new_bonus, g_.head(int(num_new_ads*0.3))])#give 30% of new ads shadow bids\n",
    "df_new_bonus['is_bonus'] = 0\n",
    "df_auction_long = pd.merge(df_auction_long, df_new_bonus, on=['p_date', 'unit_id'], how='left')\n",
    "df_auction_long = df_auction_long.fillna(1)\n",
    "df_auction_long.loc[df_auction_long['is_new']==0, 'is_bonus']= 0\n",
    "df_auction_long['new_old']=0#if new ads turn into old das\n",
    "df_auction_long.loc[(df_auction_long['is_new']==0),'new_old'] = 1\n",
    "df_auction_long = df_auction_long[['imp_id','p_date','unit_id','pxtr','auto_cpa_bid','is_new','cpm','is_bonus', 'new_old']]\n",
    "\n",
    "revenue_increase = np.zeros([10, 11,11])\n",
    "i_cnt = 0\n",
    "j_cnt = 0\n",
    "for kk in range(10):\n",
    "    for ctr_increase in np.linspace(0,0.2,11):\n",
    "        for thickness in np.linspace(0,0.05,11):\n",
    "            df_auction_long_s = df_auction_long.copy()\n",
    "            df_auction_long_s['new_old']=0\n",
    "            df_auction_long_s.loc[(df_auction_long['is_new']==0),'new_old'] = 1\n",
    "            #simulation with ctr increas and market increase\n",
    "            df_auction_long_s['new_pxtr'] = df_auction_long_s['pxtr']*(1+ctr_increase*(df_auction_long_s['new_old']))\n",
    "\n",
    "\n",
    "            df_auction_long_s['cpm'] = (1+2*df_auction_long_s['is_bonus'])*df_auction_long_s['new_pxtr']*(df_auction_long_s['auto_cpa_bid'])\n",
    "            df_auction_long_s['real_cpm'] = df_auction_long_s['new_pxtr']*(df_auction_long_s['auto_cpa_bid'])\n",
    "\n",
    "\n",
    "            df_extra = df_auction_long_s[df_auction_long_s['new_old']==1].sample(frac=thickness)\n",
    "            from numpy.random import permutation\n",
    "            idx = permutation(len(df_extra))\n",
    "            x = np.array(df_extra[['cpm','real_cpm']])[idx, :]\n",
    "            df_extra.loc[:,'cpm'] = x[:, 0]\n",
    "            df_extra.loc[:,'real_cpm'] = x[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "            df = pd.concat([df_auction_long_s, df_extra]).sort_values(by=['cpm'], ascending=False, kind='mergesort').drop_duplicates('imp_id').groupby(['p_date','is_new']).sum()['real_cpm']\n",
    "            df_auction_long_s['real_cpm'] = df_auction_long_s['pxtr']*(df_auction_long_s['auto_cpa_bid'])\n",
    "            df_no_sbl = df_auction_long_s.sort_values(by=['real_cpm'], ascending=False, kind='mergesort').drop_duplicates('imp_id').groupby(['p_date','is_new']).sum()['real_cpm']\n",
    "            df = df.reset_index()\n",
    "            df_no_sbl = df_no_sbl.reset_index()\n",
    "\n",
    "\n",
    "            a=np.array(df_no_sbl[df_no_sbl['is_new']==0]['real_cpm'])+np.array(df_no_sbl[df_no_sbl['is_new']==1]['real_cpm'])\n",
    "            b=np.array(df[df['is_new']==0]['real_cpm'])+np.array(df[df['is_new']==1]['real_cpm'])\n",
    "\n",
    "\n",
    "            revenue_increase[kk][i_cnt][j_cnt] = np.sum(b)/np.sum(a)-1\n",
    "            j_cnt+=1\n",
    "        j_cnt=0\n",
    "        i_cnt+=1\n",
    "    i_cnt=0\n",
    "    #np.save('simulation_long_term_0', revenue_increase)\n",
    "\n",
    "y = np.linspace(0,0.2,11)#ctr\n",
    "x = np.linspace(0,0.05,11)#thickness\n",
    "Z = np.zeros([11,11]) \n",
    "res = pd.DataFrame(columns=('Relative Thickness Increase', 'Relative CTR Increase' , 'revenue'))\n",
    "\n",
    "X, Y = np.meshgrid(x, y)\n",
    "for i in range(11):\n",
    "    for j in range(11):\n",
    "        Z[i, j] = np.mean(revenue_increase[:,i,j])\n",
    "        res=res.append({'Relative Thickness Increase': X[i, j], 'Relative CTR Increase': Y[i, j], 'revenue': Z[i, j]}, ignore_index=True)\n",
    "    \n",
    "res = res.pivot(\"Relative Thickness Increase\", \"Relative CTR Increase\", \"revenue\").round(4)\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax = sns.heatmap(res, annot=True)\n",
    "ax.invert_yaxis()\n",
    "#fig.savefig('Simulation.png', dpi=300) \n",
    "\n",
    "\n",
    "#simulations under [0.01, 0.02, 0.03] retention rate increase\n",
    "#with varying CTR increase and beta coefficients\n",
    "revenue_increase_2 = np.zeros([10, 11,11])#0.01\n",
    "revenue_increase_3 = np.zeros([10, 11,11])#0.02\n",
    "revenue_increase_4 = np.zeros([10, 11,11])#0.03\n",
    "i_cnt = 0\n",
    "j_cnt = 0\n",
    "for kk in range(10):\n",
    "    \n",
    "    for ctr_increase in np.linspace(0,0.15,11):\n",
    "\n",
    "        for beta_ in np.linspace(0,3,11):\n",
    "            df_auction_long_s = df_auction_long.copy()\n",
    "\n",
    "            df_auction_long_s['new_old']=0\n",
    "            df_auction_long_s.loc[(df_auction_long['is_new']==0),'new_old'] = 1\n",
    "            df_auction_long_s['new_pxtr'] = df_auction_long_s['pxtr']*(1+ctr_increase*(df_auction_long_s['new_old']))\n",
    "\n",
    "\n",
    "            df_auction_long_s['cpm'] = (1+beta_*df_auction_long_s['is_bonus'])*df_auction_long_s['new_pxtr']*(df_auction_long_s['auto_cpa_bid'])\n",
    "            df_auction_long_s['real_cpm'] = df_auction_long_s['new_pxtr']*(df_auction_long_s['auto_cpa_bid'])\n",
    "\n",
    "\n",
    "            df_extra = df_auction_long_s[df_auction_long_s['new_old']==1].sample(frac=0.01)\n",
    "            \n",
    "            idx = permutation(len(df_extra))\n",
    "            x = np.array(df_extra[['cpm','real_cpm']])[idx, :]\n",
    "            df_extra.loc[:,'cpm'] = x[:, 0]\n",
    "            df_extra.loc[:,'real_cpm'] = x[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "            df = pd.concat([df_auction_long_s, df_extra]).sort_values(by=['cpm'], ascending=False, kind='mergesort').drop_duplicates('imp_id').groupby(['p_date','is_new']).sum()['real_cpm']\n",
    "            df_auction_long_s['real_cpm'] = df_auction_long_s['pxtr']*(df_auction_long_s['auto_cpa_bid'])\n",
    "            df_no_sbl = df_auction_long_s.sort_values(by=['real_cpm'], ascending=False, kind='mergesort').drop_duplicates('imp_id').groupby(['p_date','is_new']).sum()['real_cpm']\n",
    "            df = df.reset_index()\n",
    "            df_no_sbl = df_no_sbl.reset_index()\n",
    "\n",
    "\n",
    "            a=np.array(df_no_sbl[df_no_sbl['is_new']==0]['real_cpm'])+np.array(df_no_sbl[df_no_sbl['is_new']==1]['real_cpm'])\n",
    "            b=np.array(df[df['is_new']==0]['real_cpm'])+np.array(df[df['is_new']==1]['real_cpm'])\n",
    "\n",
    "\n",
    "            revenue_increase_2[kk][i_cnt][j_cnt] = np.sum(b)/np.sum(a)-1\n",
    "            j_cnt+=1\n",
    "        j_cnt=0\n",
    "        i_cnt+=1\n",
    "    i_cnt=0\n",
    "    #np.save('simulation_long_term_2', revenue_increase_2)\n",
    "    \n",
    "    \n",
    "i_cnt = 0\n",
    "j_cnt = 0\n",
    "for kk in range(10):\n",
    "    \n",
    "    for ctr_increase in np.linspace(0,0.15,11):\n",
    "\n",
    "        for beta_ in np.linspace(0,3,11):\n",
    "            df_auction_long_s = df_auction_long.copy()\n",
    "            df_auction_long_s['new_old']=0\n",
    "            df_auction_long_s.loc[(df_auction_long['is_new']==0),'new_old'] = 1\n",
    "            df_auction_long_s['new_pxtr'] = df_auction_long_s['pxtr']*(1+ctr_increase*(df_auction_long_s['new_old']))\n",
    "\n",
    "            df_auction_long_s['cpm'] = (1+beta_*df_auction_long_s['is_bonus'])*df_auction_long_s['new_pxtr']*(df_auction_long_s['auto_cpa_bid'])\n",
    "            df_auction_long_s['real_cpm'] = df_auction_long_s['new_pxtr']*(df_auction_long_s['auto_cpa_bid'])\n",
    "\n",
    "\n",
    "            df_extra = df_auction_long_s[df_auction_long_s['new_old']==1].sample(frac=0.02)\n",
    "            idx = permutation(len(df_extra))\n",
    "            x = np.array(df_extra[['cpm','real_cpm']])[idx, :]\n",
    "            df_extra.loc[:,'cpm'] = x[:, 0]\n",
    "            df_extra.loc[:,'real_cpm'] = x[:, 1]\n",
    "\n",
    "            df = pd.concat([df_auction_long_s, df_extra]).sort_values(by=['cpm'], ascending=False, kind='mergesort').drop_duplicates('imp_id').groupby(['p_date','is_new']).sum()['real_cpm']\n",
    "            df_auction_long_s['real_cpm'] = df_auction_long_s['pxtr']*(df_auction_long_s['auto_cpa_bid'])\n",
    "            df_no_sbl = df_auction_long_s.sort_values(by=['real_cpm'], ascending=False, kind='mergesort').drop_duplicates('imp_id').groupby(['p_date','is_new']).sum()['real_cpm']\n",
    "            df = df.reset_index()\n",
    "            df_no_sbl = df_no_sbl.reset_index()\n",
    "\n",
    "\n",
    "            a=np.array(df_no_sbl[df_no_sbl['is_new']==0]['real_cpm'])+np.array(df_no_sbl[df_no_sbl['is_new']==1]['real_cpm'])\n",
    "            b=np.array(df[df['is_new']==0]['real_cpm'])+np.array(df[df['is_new']==1]['real_cpm'])\n",
    "\n",
    "\n",
    "            revenue_increase_3[kk][i_cnt][j_cnt] = np.sum(b)/np.sum(a)-1\n",
    "            j_cnt+=1\n",
    "        j_cnt=0\n",
    "        i_cnt+=1\n",
    "    i_cnt=0\n",
    "\n",
    "    #np.save('simulation_long_term_3', revenue_increase_3)\n",
    "    \n",
    "    \n",
    "i_cnt = 0\n",
    "j_cnt = 0\n",
    "for kk in range(10):\n",
    "    \n",
    "    for ctr_increase in np.linspace(0,0.15,11):\n",
    "\n",
    "        for beta_ in np.linspace(0,3,11):\n",
    "            df_auction_long_s = df_auction_long.copy()\n",
    "\n",
    "            df_auction_long_s['new_old']=0\n",
    "            df_auction_long_s.loc[(df_auction_long['is_new']==0),'new_old'] = 1\n",
    "            df_auction_long_s['new_pxtr'] = df_auction_long_s['pxtr']*(1+ctr_increase*(df_auction_long_s['new_old']))\n",
    "\n",
    "\n",
    "            df_auction_long_s['cpm'] = (1+beta_*df_auction_long_s['is_bonus'])*df_auction_long_s['new_pxtr']*(df_auction_long_s['auto_cpa_bid'])\n",
    "            df_auction_long_s['real_cpm'] = df_auction_long_s['new_pxtr']*(df_auction_long_s['auto_cpa_bid'])\n",
    "\n",
    "\n",
    "            df_extra = df_auction_long_s[df_auction_long_s['new_old']==1].sample(frac=0.03)\n",
    "            #from numpy.random import permutation\n",
    "            idx = permutation(len(df_extra))\n",
    "            x = np.array(df_extra[['cpm','real_cpm']])[idx, :]\n",
    "            df_extra.loc[:,'cpm'] = x[:, 0]\n",
    "            df_extra.loc[:,'real_cpm'] = x[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "            df = pd.concat([df_auction_long_s, df_extra]).sort_values(by=['cpm'], ascending=False, kind='mergesort').drop_duplicates('imp_id').groupby(['p_date','is_new']).sum()['real_cpm']\n",
    "            df_auction_long_s['real_cpm'] = df_auction_long_s['pxtr']*(df_auction_long_s['auto_cpa_bid'])\n",
    "            df_no_sbl = df_auction_long_s.sort_values(by=['real_cpm'], ascending=False, kind='mergesort').drop_duplicates('imp_id').groupby(['p_date','is_new']).sum()['real_cpm']\n",
    "            df = df.reset_index()\n",
    "            df_no_sbl = df_no_sbl.reset_index()\n",
    "\n",
    "\n",
    "            a=np.array(df_no_sbl[df_no_sbl['is_new']==0]['real_cpm'])+np.array(df_no_sbl[df_no_sbl['is_new']==1]['real_cpm'])\n",
    "            b=np.array(df[df['is_new']==0]['real_cpm'])+np.array(df[df['is_new']==1]['real_cpm'])\n",
    "\n",
    "\n",
    "            revenue_increase_4[kk][i_cnt][j_cnt] = np.sum(b)/np.sum(a)-1\n",
    "            j_cnt+=1\n",
    "        j_cnt=0\n",
    "        i_cnt+=1\n",
    "    i_cnt=0\n",
    "    #np.save('simulation_long_term_4', revenue_increase_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677e6825",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "282.9779357910156px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
